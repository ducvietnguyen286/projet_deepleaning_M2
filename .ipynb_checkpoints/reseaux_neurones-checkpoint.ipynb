{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3824fdbc",
   "metadata": {},
   "source": [
    "# Réseaux de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0bddcf",
   "metadata": {},
   "source": [
    "Voici la liste des réseaux de neurones que nous allons implémenter :\n",
    "\n",
    "1. DNN\n",
    "2. LSTM\n",
    "3. GRU\n",
    "4. BRNN\n",
    "5. RCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7cd05a",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e317d7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional, Input, Reshape, GRU, Convolution1D, Flatten\n",
    "from sklearn import metrics\n",
    "from keras import backend as K\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f53771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D, AveragePooling1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "import pathlib\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "import time\n",
    "import os\n",
    "!pip install memory_profiler\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a923d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyyaml h5py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42911fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4df5657",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"opinion_fact_news_pretraiter.csv\")\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f474a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"label\"] == \"fact\",\"label\"] = 1\n",
    "df.loc[df[\"label\"] == \"opinion\",\"label\"] = 0\n",
    "df['label']=df['label'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ca883",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['body'] \n",
    "ylabels = df['label'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c4f537",
   "metadata": {},
   "source": [
    "### Bow (Bag of Word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a25ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "X_clear = []\n",
    "for x in X:\n",
    " paragraph = gensim.utils.simple_preprocess(x)\n",
    " paragraph = ' '.join(paragraph)\n",
    " X_clear.append(paragraph)\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "vectorizer.fit(X_clear)\n",
    "\n",
    "\n",
    "X_data_count = vectorizer.transform(X_clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7687dde",
   "metadata": {},
   "source": [
    "### Tf-Idf  (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a750b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer='word', max_features=30000)\n",
    "tfidf_vect.fit(X_clear)\n",
    "X_data_tfidf =  tfidf_vect.transform(X_clear)\n",
    "\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', max_features=30000, ngram_range=(3, 3))\n",
    "tfidf_vect_ngram.fit(X_clear)\n",
    "X_data_tfidf_ngram =  tfidf_vect_ngram.transform(X_clear)\n",
    "\n",
    "tfidf_vect_ngram_char = TfidfVectorizer(analyzer='char', max_features=30000, ngram_range=(3, 3))\n",
    "tfidf_vect_ngram_char.fit(X_clear)\n",
    "X_data_tfidf_ngram_char =  tfidf_vect_ngram_char.transform(X_clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d48dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "svd.fit(X_data_tfidf)\n",
    "X_data_tfidf_svd = svd.transform(X_data_tfidf)\n",
    "\n",
    "svd_ngram = TruncatedSVD(n_components=300, random_state=42)\n",
    "svd_ngram.fit(X_data_tfidf_ngram)\n",
    "X_data_tfidf_ngram_svd = svd_ngram.transform(X_data_tfidf_ngram)\n",
    "\n",
    "svd_ngram_char = TruncatedSVD(n_components=300, random_state=42)\n",
    "svd_ngram_char.fit(X_data_tfidf_ngram_char)\n",
    "X_data_tfidf_ngram_char_svd = svd_ngram_char.transform(X_data_tfidf_ngram_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f58b2f",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b6565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_DNN(nom, X_data,Y_data,n_epochs, drop_Out):\n",
    "  verbose , batch_size = 0 , 32\n",
    "  X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=42,stratify=Y_data)\n",
    "  \n",
    "  input_layer = Input(shape=(300,))\n",
    "\n",
    "  layer = Dense(1024, activation='relu')(input_layer)\n",
    "  layer = Dropout(drop_Out)(layer)\n",
    "  layer = Dense(1024, activation='relu')(layer)\n",
    "  layer = Dense(512, activation='relu')(layer)\n",
    "  output_layer = Dense(1, activation='sigmoid')(layer)\n",
    "  \n",
    "  model = models.Model(input_layer, output_layer)\n",
    "\n",
    "  start_time_train = time.time()\n",
    "  model.compile(\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=n_epochs, batch_size=512)\n",
    "  end_time_train = time.time()\n",
    "  time_train= (end_time_train - start_time_train)*1000\n",
    "  time_train_val = round(time_train)\n",
    "\n",
    "\n",
    "  accuracy = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=0)\n",
    "  start_time_test = time.time()\n",
    "  y_pred = model.predict(X_test)\n",
    "  end_time_test = time.time()\n",
    "  time_test= (end_time_test - start_time_test)*1000\n",
    "  time_test_val=round(time_test)\n",
    "  y_pred = np.around(y_pred, 0)\n",
    "  #df_resultDL.loc[(len(df_resultDL)+1)] = {'Nom': nom, 'Drop_out': drop_Out,'Accuracy': metrics.accuracy_score(test_predictions, Y_test), 'Precision': metrics.precision_score(test_predictions, Y_test), 'Recall' : metrics.recall_score(test_predictions, Y_test)}\n",
    "  print(\"Accuracy: \", metrics.accuracy_score(y_pred, Y_test))\n",
    "  #co the sai---------------------------------------------\n",
    "  start_time_test = time.time()\n",
    "  model.predict(X_test)\n",
    "  end_time_test = time.time()\n",
    "  time_test= (end_time_test - start_time_test)*1000\n",
    "  time_test_val=round(time_test)\n",
    "  #--------------------------------------------------------------------------\n",
    "  tracemalloc.start()\n",
    "  model.predict(X_test)\n",
    "  snapshot = tracemalloc.take_snapshot()\n",
    "  top_stats = snapshot.statistics('traceback')\n",
    "  stat = top_stats[0]\n",
    "  mem_test = round(stat.size/1024)\n",
    "  #------------------------------------------------------------\n",
    "  # converture y_pred\n",
    " # output_TF=model.predict(X_test)\n",
    " #y_pred=(np.argmax(output_TF,axis=1)+1)\n",
    "  \n",
    "  precision = metrics.precision_score(y_pred,Y_test)\n",
    "  precision_val=round(precision,4)\n",
    "\n",
    "  recall= metrics.recall_score(y_pred,Y_test,average='macro')\n",
    "  recal_val=round(recall,4)\n",
    " \n",
    "  f1=metrics.f1_score(y_pred,Y_test,average='macro')\n",
    "  f1_val=round(f1,4)\n",
    "  \n",
    "  accuracy_test = metrics.accuracy_score(y_pred,Y_test)\n",
    "  accuracy_test_val = round(accuracy_test,4)\n",
    "\n",
    "  params = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
    "  \n",
    "  export_dir=\"save_model/DNN\"\n",
    "\n",
    "  model.save(export_dir)\n",
    "\n",
    "  model=tf.keras.models.load_model(export_dir)  \n",
    "\n",
    "  taille= os.stat('save_model/DNN').st_size\n",
    "\n",
    "  return [nom,n_epochs,drop_Out,precision_val,recal_val,f1_val,accuracy_test_val,time_train_val, time_test_val,mem_test,params,taille]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a324c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "def run_experiment():\n",
    "  with open('resultat_DNN.txt', 'w') as f:\n",
    "    for dropOut in [0, 0.2,0.5,0.8]:\n",
    "      score= evaluate_model_DNN(nom='Deep_Neural_Network', X_data = X_data_tfidf_svd, Y_data = ylabels, n_epochs=20,drop_Out= dropOut)\n",
    "      #print(score)\n",
    "      f.write(\"{0}\".format(score))\n",
    "      scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c6fd22",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c775362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_LSTM(nom, X_data,Y_data,n_epochs, drop_Out):\n",
    "  verbose , batch_size = 0 , 32\n",
    "  X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=42,stratify=Y_data)\n",
    "  \n",
    "  input_layer = Input(shape=(300,))\n",
    "\n",
    "  layer = Reshape((10, 30))(input_layer)\n",
    "  layer = LSTM(256, activation='relu', return_sequences=True)(layer)\n",
    "  layer = Dropout(drop_Out)(layer)\n",
    "  layer = LSTM(128, activation='relu')(layer)\n",
    "  layer = Dense(512, activation='relu')(layer)\n",
    "  layer = Dense(512, activation='relu')(layer)\n",
    "  layer = Dense(128, activation='relu')(layer)\n",
    "  output_layer = Dense(1, activation='sigmoid')(layer)\n",
    "\n",
    "  model = models.Model(input_layer, output_layer)\n",
    "\n",
    "  start_time_train = time.time()\n",
    "  model.compile(\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=n_epochs, batch_size=512)\n",
    "  end_time_train = time.time()\n",
    "  time_train= (end_time_train - start_time_train)*1000\n",
    "  time_train_val = round(time_train)\n",
    "\n",
    "\n",
    "  accuracy = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=0)\n",
    "  start_time_test = time.time()\n",
    "  y_pred = model.predict(X_test)\n",
    "  end_time_test = time.time()\n",
    "  time_test= (end_time_test - start_time_test)*1000\n",
    "  time_test_val=round(time_test)\n",
    "  y_pred = np.around(y_pred, 0)\n",
    "  #df_resultDL.loc[(len(df_resultDL)+1)] = {'Nom': nom, 'Drop_out': drop_Out,'Accuracy': metrics.accuracy_score(test_predictions, Y_test), 'Precision': metrics.precision_score(test_predictions, Y_test), 'Recall' : metrics.recall_score(test_predictions, Y_test)}\n",
    "  print(\"Accuracy: \", metrics.accuracy_score(y_pred, Y_test))\n",
    "  #co the sai---------------------------------------------\n",
    "  start_time_test = time.time()\n",
    "  model.predict(X_test)\n",
    "  end_time_test = time.time()\n",
    "  time_test= (end_time_test - start_time_test)*1000\n",
    "  time_test_val=round(time_test)\n",
    "  #--------------------------------------------------------------------------\n",
    "  tracemalloc.start()\n",
    "  model.predict(X_test)\n",
    "  snapshot = tracemalloc.take_snapshot()\n",
    "  top_stats = snapshot.statistics('traceback')\n",
    "  stat = top_stats[0]\n",
    "  mem_test = round(stat.size/1024)\n",
    "  #------------------------------------------------------------\n",
    "  # converture y_pred\n",
    " # output_TF=model.predict(X_test)\n",
    " #y_pred=(np.argmax(output_TF,axis=1)+1)\n",
    "\n",
    "  precision = metrics.precision_score(y_pred,Y_test)\n",
    "  precision_val=round(precision,4)\n",
    " \n",
    "  recall= metrics.recall_score(y_pred,Y_test,average='macro')\n",
    "  recal_val=round(recall,4)\n",
    "\n",
    "  f1=metrics.f1_score(y_pred,Y_test,average='macro')\n",
    "  f1_val=round(f1,4)\n",
    " \n",
    "  accuracy_test = metrics.accuracy_score(y_pred,Y_test)\n",
    "  accuracy_test_val = round(accuracy_test,4)\n",
    "\n",
    "  params = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
    "\n",
    "  export_dir=\"save_model/DNN\"\n",
    "\n",
    "  model.save(export_dir)\n",
    "\n",
    "  model=tf.keras.models.load_model(export_dir)  \n",
    "\n",
    "  taille= os.stat('save_model/DNN').st_size   \n",
    "\n",
    "  return [nom,n_epochs,drop_Out,precision_val,recal_val,f1_val,accuracy_test_val,time_train_val, time_test_val,mem_test,params,taille]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f97fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "def run_experiment():\n",
    "  with open('save_model/resultat_LSTM.txt', 'w') as f:\n",
    "    for dropOut in [0, 0.2,0.5,0.8]:\n",
    "      score= evaluate_model_LSTM(nom='LSTM', X_data = X_data_tfidf_svd, Y_data = ylabels, n_epochs=20,drop_Out= dropOut)\n",
    "      #print(score)\n",
    "      f.write(\"{0}\".format(score))\n",
    "      scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02b107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70620a70",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b32dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_GRU(nom, X_data,Y_data,n_epochs, drop_Out):\n",
    "  verbose , batch_size = 0 , 32\n",
    "  X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=42,stratify=Y_data)\n",
    "  \n",
    "  input_layer = Input(shape=(300,))\n",
    "\n",
    "  layer = Reshape((10, 30))(input_layer)\n",
    "  layer = GRU(128, activation='relu')(layer)\n",
    "  layer = Dropout(drop_Out)(layer)\n",
    " # layer = GRU(64, activation='relu')(layer)\n",
    "  layer = Dense(256, activation='relu')(layer)\n",
    "  layer = Dense(128, activation='relu')(layer)\n",
    "  output_layer = Dense(1, activation='sigmoid')(layer)\n",
    "\n",
    "  model = models.Model(input_layer, output_layer)\n",
    "\n",
    "  start_time_train = time.time()\n",
    "  model.compile(\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=n_epochs, batch_size=512)\n",
    "  end_time_train = time.time()\n",
    "  time_train= (end_time_train - start_time_train)*1000\n",
    "  time_train_val = round(time_train)\n",
    "\n",
    "\n",
    "  accuracy = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=0)\n",
    "  start_time_test = time.time()\n",
    "  y_pred = model.predict(X_test)\n",
    "  end_time_test = time.time()\n",
    "  time_test= (end_time_test - start_time_test)*1000\n",
    "  time_test_val=round(time_test)\n",
    "  y_pred = np.around(y_pred, 0)\n",
    "\n",
    "  print(\"Accuracy: \", metrics.accuracy_score(y_pred, Y_test))\n",
    "\n",
    "  start_time_test = time.time()\n",
    "  model.predict(X_test)\n",
    "  end_time_test = time.time()\n",
    "  time_test= (end_time_test - start_time_test)*1000\n",
    "  time_test_val=round(time_test)\n",
    "\n",
    "  tracemalloc.start()\n",
    "  model.predict(X_test)\n",
    "  snapshot = tracemalloc.take_snapshot()\n",
    "  top_stats = snapshot.statistics('traceback')\n",
    "  stat = top_stats[0]\n",
    "  mem_test = round(stat.size/1024)\n",
    "  \n",
    "  precision = metrics.precision_score(y_pred,Y_test)\n",
    "  precision_val=round(precision,4)\n",
    "\n",
    "  recall= metrics.recall_score(y_pred,Y_test,average='macro')\n",
    "  recal_val=round(recall,4)\n",
    "\n",
    "  f1=metrics.f1_score(y_pred,Y_test,average='macro')\n",
    "  f1_val=round(f1,4)\n",
    "\n",
    "  accuracy_test = metrics.accuracy_score(y_pred,Y_test)\n",
    "  accuracy_test_val = round(accuracy_test,4)\n",
    "\n",
    "  params = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
    "\n",
    "  export_dir=\"save_model/GRU\"\n",
    "\n",
    "  model.save(export_dir)\n",
    "\n",
    "  model=tf.keras.models.load_model(export_dir)  \n",
    "\n",
    "  taille= os.stat('save_model/GRU').st_size   \n",
    "\n",
    "  return [nom,n_epochs,drop_Out,precision_val,recal_val,f1_val,accuracy_test_val,time_train_val, time_test_val,mem_test,params,taille]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "def run_experiment():\n",
    "  with open('save_model/resultat_GRU.txt', 'w') as f:\n",
    "    for dropOut in [0, 0.2,0.5,0.8]:\n",
    "      score= evaluate_model_GRU(nom='GRU', X_data = X_data_tfidf_svd, Y_data = ylabels, n_epochs=20,drop_Out= dropOut)\n",
    "      #print(score)\n",
    "      f.write(\"{0}\".format(score))\n",
    "      scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa8bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e60b5",
   "metadata": {},
   "source": [
    "## Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c3121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_BRNN(nom, X_data,Y_data,n_epochs, drop_Out):\n",
    "  verbose , batch_size = 0 , 32\n",
    "  X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=42,stratify=Y_data)\n",
    "  \n",
    "  input_layer = Input(shape=(300,))\n",
    "\n",
    "  layer = Reshape((10, 30))(input_layer)\n",
    "  layer = Bidirectional(GRU(128, activation='relu'))(layer)\n",
    "  layer = Dropout(drop_Out)(layer)\n",
    "  layer = Dense(512, activation='relu')(layer)\n",
    "  layer = Dense(512, activation='relu')(layer)\n",
    "  layer = Dense(128, activation='relu')(layer)\n",
    "  output_layer = Dense(1, activation='sigmoid')(layer)\n",
    "\n",
    "  model = models.Model(input_layer, output_layer)\n",
    "\n",
    "  start_time_train = time.time()\n",
    "  model.compile(\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=n_epochs, batch_size=512)\n",
    "  end_time_train = time.time()\n",
    "  time_train= (end_time_train - start_time_train)*1000\n",
    "  time_train_val = round(time_train)\n",
    "\n",
    "\n",
    "  accuracy = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=0)\n",
    "  start_time_test = time.time()\n",
    "  y_pred = model.predict(X_test)\n",
    "  end_time_test = time.time()\n",
    "  time_test= (end_time_test - start_time_test)*1000\n",
    "  time_test_val=round(time_test)\n",
    "  y_pred = np.around(y_pred, 0)\n",
    "\n",
    "  print(\"Accuracy: \", metrics.accuracy_score(y_pred, Y_test))\n",
    "\n",
    "  start_time_test = time.time()\n",
    "  model.predict(X_test)\n",
    "  end_time_test = time.time()\n",
    "  time_test= (end_time_test - start_time_test)*1000\n",
    "  time_test_val=round(time_test)\n",
    "\n",
    "  tracemalloc.start()\n",
    "  model.predict(X_test)\n",
    "  snapshot = tracemalloc.take_snapshot()\n",
    "  top_stats = snapshot.statistics('traceback')\n",
    "  stat = top_stats[0]\n",
    "  mem_test = round(stat.size/1024)\n",
    "  \n",
    "  precision = metrics.precision_score(y_pred,Y_test)\n",
    "  precision_val=round(precision,4)\n",
    "\n",
    "  recall= metrics.recall_score(y_pred,Y_test,average='macro')\n",
    "  recal_val=round(recall,4)\n",
    "\n",
    "  f1=metrics.f1_score(y_pred,Y_test,average='macro')\n",
    "  f1_val=round(f1,4)\n",
    "\n",
    "  accuracy_test = metrics.accuracy_score(y_pred,Y_test)\n",
    "  accuracy_test_val = round(accuracy_test,4)\n",
    "\n",
    "  params = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
    "\n",
    "  export_dir=\"save_model/BRNN\"\n",
    "\n",
    "  model.save(export_dir)\n",
    "\n",
    "  model=tf.keras.models.load_model(export_dir)  \n",
    "\n",
    "  taille= os.stat('save_model/BRNN').st_size   \n",
    "\n",
    "  return [nom,n_epochs,drop_Out,precision_val,recal_val,f1_val,accuracy_test_val,time_train_val, time_test_val,mem_test,params,taille]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2623d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "def run_experiment():\n",
    "  with open('save_model/resultat_BRNN.txt', 'w') as f:\n",
    "    for dropOut in [0, 0.2,0.5,0.8]:\n",
    "      score= evaluate_model_BRNN(nom='BRNN', X_data = X_data_tfidf_svd, Y_data = ylabels, n_epochs=20,drop_Out= dropOut)\n",
    "      #print(score)\n",
    "      f.write(\"{0}\".format(score))\n",
    "      scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1488f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287bfc31",
   "metadata": {},
   "source": [
    "## RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_RCNN(nom, X_data,Y_data,n_epochs, drop_Out):\n",
    "  verbose , batch_size = 0 , 32\n",
    "  X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=42,stratify=Y_data)\n",
    "  \n",
    "  input_layer = Input(shape=(300,))\n",
    "\n",
    "  layer = Reshape((10, 30))(input_layer)\n",
    "  \n",
    "  layer = Convolution1D(128, 7, activation=\"relu\")(layer)\n",
    "  layer = Convolution1D(128, 3, activation=\"relu\")(layer)\n",
    "  layer = Dropout(drop_Out)(layer)\n",
    "  layer = Flatten()(layer)\n",
    "  layer = Dense(512, activation='relu')(layer)\n",
    "  layer = Dense(512, activation='relu')(layer)\n",
    "  layer = Dense(128, activation='relu')(layer)\n",
    "  output_layer = Dense(1, activation='sigmoid')(layer)\n",
    "\n",
    "\n",
    "  model = models.Model(input_layer, output_layer)\n",
    "\n",
    "  start_time_train = time.time()\n",
    "  model.compile(\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=n_epochs, batch_size=512)\n",
    "  end_time_train = time.time()\n",
    "  time_train= (end_time_train - start_time_train)*1000\n",
    "  time_train_val = round(time_train)\n",
    "\n",
    "\n",
    "  accuracy = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=0)\n",
    "  start_time_test = time.time()\n",
    "  y_pred = model.predict(X_test)\n",
    "  end_time_test = time.time()\n",
    "  time_test= (end_time_test - start_time_test)*1000\n",
    "  time_test_val=round(time_test)\n",
    "  y_pred = np.around(y_pred, 0)\n",
    "\n",
    "  print(\"Accuracy: \", metrics.accuracy_score(y_pred, Y_test))\n",
    "\n",
    "  start_time_test = time.time()\n",
    "  model.predict(X_test)\n",
    "  end_time_test = time.time()\n",
    "  time_test= (end_time_test - start_time_test)*1000\n",
    "  time_test_val=round(time_test)\n",
    "\n",
    "  tracemalloc.start()\n",
    "  model.predict(X_test)\n",
    "  snapshot = tracemalloc.take_snapshot()\n",
    "  top_stats = snapshot.statistics('traceback')\n",
    "  stat = top_stats[0]\n",
    "  mem_test = round(stat.size/1024)\n",
    "  \n",
    "  precision = metrics.precision_score(y_pred,Y_test,average='macro')\n",
    "  precision_val=round(precision,4)\n",
    "\n",
    "  recall= metrics.recall_score(y_pred,Y_test,average='macro')\n",
    "  recal_val=round(recall,4)\n",
    "\n",
    "  f1=metrics.f1_score(y_pred,Y_test,average='macro')\n",
    "  f1_val=round(f1,4)\n",
    "\n",
    "  accuracy_test = metrics.accuracy_score(y_pred,Y_test)\n",
    "  accuracy_test_val = round(accuracy_test,4)\n",
    "\n",
    "  params = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
    "\n",
    "  export_dir=\"save_model/RCNN\"\n",
    "\n",
    "  model.save(export_dir)\n",
    "\n",
    "  model=tf.keras.models.load_model(export_dir)  \n",
    "\n",
    "  taille= os.stat('save_model/RCNN').st_size   \n",
    "\n",
    "  return [nom,n_epochs,drop_Out,precision_val,recal_val,f1_val,accuracy_test_val,time_train_val, time_test_val,mem_test,params,taille]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "def run_experiment():\n",
    "  with open('save_model/resultat_RCNN.txt', 'w') as f:\n",
    "    for dropOut in [0, 0.2,0.5,0.8]:\n",
    "      score= evaluate_model_RCNN(nom='RCNN', X_data = X_data_tfidf_svd, Y_data = ylabels, n_epochs=20,drop_Out= dropOut)\n",
    "      #print(score)\n",
    "      f.write(\"{0}\".format(score))\n",
    "      scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffca75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=run_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
